# Week10

本周内容：大数据机器学习，前沿话题

## 10.1 大数据梯度下降


#### 10.1.1 大数据学习

引入
- 样本m的个数曲线：过拟合和欠拟合
- 样本数$m < 1000$，一般容易过拟合

![](https://user-images.githubusercontent.com/41643043/56872494-6d9c3500-6a5c-11e9-9451-d3554da613f7.png)


大数据优势和缺点
- 数据量大，避免模型过拟合
- 缺点：数据量大，梯度下降计算量大



处理大数据的优化算法
- 随机梯度下降
- 映射化简(map-reduce)

#### 10.1.2 随机梯度下降
梯度下降
- 正常的梯度下降也叫 batch gradient descent，即计算$\theta$的时候使用整个 batch 
- 已经忘记梯度下降怎么来的，为什么来的，等会查看一下，$\alpha$整个公式！！！！

随机梯度下降
- 随机打乱样本顺序
    - 从第二步的算法来看，其实是加速你的收敛了随机梯度下降

![](https://user-images.githubusercontent.com/41643043/56872739-f2884e00-6a5e-11e9-87ad-6f4e8dd3a30b.png)

- 单个样本随机求梯度，进行计算

- 单样本收敛速度更快
- 但是会有梯度方向的反复，采用迂回，可能会收敛到最低点
- 但只要接近最低点的附近区域进行震荡，都能得到一个不错的假设函数，都不是太大的问题

随机梯度下降收敛快的原因
- 单样本进行内循环，速度当然要比多样本计算梯度要快
- 随机打乱样本顺序，样本具有一般性，不会出现顺序的特性


#### 10.1.3 小批量梯度下降
小批量梯度下降(mini-batch GD)
- 用的是小批量的样本，每次使用 b (2-100) 个样本
- 收敛速度肯定比梯度下降要快
    - 因为 b 个样本就可以进行速度优化了
- 收敛速度可能比随机梯度下降速度要快
    - 什么时候速度要比sgd快
    - 向量化
    - 使用有些库，这些库每次能并行处理 b 个样本，
    - 而sgd每次只能使计算一个样本
- 缺点是多了个参数b，需要每次进行调试
    - 好的向量化实现，速度可能比sgd快


#### 10.1.3 随机梯度下降收敛调试

调试随机梯度下降
- 迭代的时候，每次对最后1000个样本进行进行本轮的求平均，能得到反馈曲线
- 随着迭代次数上升，逐渐降低学习率的值，将对随机梯度下降有很好的收敛

![](https://user-images.githubusercontent.com/41643043/56880643-292a8c80-6a90-11e9-8910-76ef7e468b28.png)
- 图1降低学习率，能使迭代曲线下降
- 图2增加最后平均样本的数量，能是下降曲线更加平滑
- 图3增加最后平均样本的数量，能是下降曲线更加平滑，但没有改善
- 图4结果已经发散，需要降低学习率，使代价函数下降


## 10.2 前沿话题

#### 10.2.1 在线学习

预测点击率 $click\ through\ rate$









#### 10.2.2 Map-Reduce和数据平行运算


批量梯度下降
- 有 400 个样本需要计算
- Map-Reduce 使用 4 台电脑
    - 每台电脑 100 个样本并行计算，速度是原来的 4 倍
    - master 电脑 整合4台电脑的数据


集群map-reduce
- 利用多台机器运行分别计算少量样本
- 中心服务器，整合所有机器的结果，进行求和
![](https://user-images.githubusercontent.com/41643043/56879324-cedafd00-6a8a-11e9-8e18-2996228c9545.png)


单机多核map-reduce
- 单机上面有多个核心，可以用map-reduce
- 相比集群，单机没有网络延迟，有些ml库支持单机并行运行，所以有时候不需要设置并行运行

什么时候能使用map-reduce
- 采用计算求和的时候$\sum$
- 但多次更新参数这种，就不行了






